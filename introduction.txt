In this video and the next couple we're gonna try to answer a very basic question. What is LangChain and why do we choose to use it at all? What is it really doing for us? Now, answering this question is a little bit more challenging than you might expect. So to answer it, we're gonna go through a little bit of a process, in this video and the next couple. So here's what we're gonna do. We're gonna take a look at a public web application called pdf.ai. This is a web app. I did not put it together. Some other people put it together. It takes a PDF document and allows you to ask ChatGPT questions about the contents of the document. So I'm gonna give you a quick demonstration of it in just a moment. Once we understand what this app is doing, we're gonna go a little bit behind the scenes and understand how this application probably works, how it somehow reads the PDF and somehow gets ChatGPT to ask or answer questions about it. And then once we understand how this application works, we're gonna use that knowledge to better understand what LangChain is doing for us. So a little bit involved here right at the start of the course. I know, but trust me, it's all gonna come together. This is really gonna give you a really good overview on some of the current state-of-the-art stuff in text generation. So let's get to it. Quick demonstration. I'm gonna open up my browser and go to pdf.ai. Now you do not have to do this. This is not required. This is just a very quick demonstration. So at this page you'll see it says okay, you can chat with a document. So basically you can upload a PDF ask questions, it all gets sent off to ChatGPT and ChatGPT somehow answers questions about your document. Now to show you how this thing works, I've taken a Wikipedia article about the planet earth. There are 45 pages of content in this PDF and it's a ton of text all about Earth. So it's composition, it's history, why it's called Earth, so etymology of the word Earth. Basically everything you can possibly imagine about Earth. There's a lot of information in this document. So I wanna somehow quickly summarize it and get some really basic understanding of what's inside. So I'm gonna take that document and I'm gonna upload it to pdf.ai. You'll notice I've already logged in ahead of time here. So here we go. I'm gonna upload it, like so, click upload. And then after the briefest pause, like it's really quite fast, I can then view this document. Here we go. Here's the document on the left hand side, and then I can ask questions about it on the right hand side. So one thing that this document talks about is why Earth is called Earth. And you'll notice there's a section right here called etymology and it says "Modern English Earth is from the word erode" or something like that. So clearly there's some content in this PDF about why the earth is called Earth. So just keep that in mind for a second. I'm gonna ask a question here. I'm gonna say, why is the, or how about we'll do, where does the name Earth come from? I think that's a little bit better. So I'm gonna send that off and then we'll very get, quickly get a response here. And if you look carefully at the response, it's almost an exact copy paste of that little chunk of text right there. So it's very clear that this tool, pdf.ai, has somehow extracted some meaning from this PDF and gotten ChatGPT to answer some questions about it. And what's also really neat here is we can click on these links and we'll be told what the kind of source or why decided or really a resource, a citation for giving this particular answer. So it's pretty clear that, yeah, this tool definitely works and it's pretty neat. It's so neat in fact that we're actually gonna end up building an exact clone of this, just about an exact clone later on inside the course. So trust me, you're really gonna come to understand how this thing is truly working. Alright, so now that we've seen this application, quick pause here. We'll come back in just a moment. I'm gonna give you some behind the scenes look at what this app is really doing and how it can understand what is inside of a PDF.

All right, this is where the fun really begins. This is where we're gonna start to understand what's going on behind the scenes. Now, like I said, I'm gonna tell you how this application is working. You do not have to memorize any of this right now 'cause we're going to eventually build a clone of this application. And at that point, well, then you'll get a really in-depth explanation of everything that's going on. So for right now, just kind of a high-level overview. Okay, so I'm gonna show you two possible ways of making this application work. The first way is not gonna be that great, I just wanna mention it, I'm go into the second way, which is a little bit better. So option number one for answering a user's question. Whenever a user enters a question into that web app, we could take all the text from the PDF, I mean all the text from every page, and we could send both these in a prompt off to ChatGPT and just hope that ChatGPT answers this question correctly. Now, like I said, this is not gonna work out too well for a couple of different reasons. First, we can only send a limited amount of text off to ChatGPT. If you send anything longer than that, ChatGPT is just gonna immediately throw in air. And I can prove that to you very easily. If I go over to the PDF, copy everything, I'll paste it into ChatGPT, and then put in my question. So where does the word earth come from? And very quickly we'll see, yeah, we just get an error. It says the message was too long. Now, even if we could put in as much text to ChatGPT as we wanted, we usually do not want to do that because chat models usually don't do well with a ton of text. They have a much harder time of understanding or pulling some real discreet meaning out of all that text. So shorter messages are almost always better. And finally, the more texts we send off to ChatGPT, the more money we have to pay for each individual request. So at some point in time, it really is just a financial issue. We don't want to be paying ChatGPT tons and tons of money to answer questions about a PDF. So obviously, option number one, not that great. Let's take a look at option number two. So option number two, yep, this is what we're gonna be doing in our application and this is also very likely what PDF.ai is doing as well. So everything begins whenever a user uploads a PDF. Whenever a PDF is uploaded, all the text is extracted and divided up into chunks. We then run a algorithm over each individual chunk to generate a summary of what that chunk is talking about. We then take those summaries and we store them in a database. Steps one and two occur instantly whenever someone uploads A PDF. After we've generated those summaries, we then kind of wait around. We wait for a user to ask a question. So later on, whenever user does ask a question, we're gonna take a look at their question, we're gonna try to figure out what is it is asking about, and we're gonna take a look at all those text summaries that we had stored inside of a database and we're gonna try to find the most relevant chunk of text. Once we've found the most relevant chunk of text, we're gonna send that plus the user's question off to ChatGPT. Now this is a high-level overview, so let me show you just a couple of diagrams to really flesh out this entire process and give a little bit more meaning to it, because understanding what's going on behind these different steps, yeah, that's where you're gonna understand why we use LangChain at all. Okay, so here we go. Here's a little bit more detail on steps one through four. So step one, super simple. Yeah, we just take all this text, we extract into one big document, one big BLOB. So that's all the pages altogether. Once we've got all that text, we divide it up into chunks. By default, usually we might use a chunk size of 1000 characters. And that means that every chunk is gonna be 1000 characters long. But we can absolutely configure that. There's some considerations over what an ideal length is. Of course, that's something we will discuss later on. Once we have these text chunks, we then start to do a little bit of magic. This is where things start to get really interesting. So we take each of these text chunks and we feed them into something called an embedding creation algorithm. And based on the name of that, as you guessed, this creates something called an embedding. So let me very quickly tell you what an embedding is because this is gonna be a super key topic throughout the course; it's gonna be something we come back to very, very often. An embedding takes a string and turns it into an array of numbers. This array of numbers, for the algorithm that you and I are going to use, is always gonna be 1,536 elements long. So I'm only showing four numbers right here, but in reality there will be 1,536. Each of these numbers is gonna be between -1 and 1. This array of numbers can be thought of as distilling the raw and essence of what this text is talking about. So for example, if I feed the text, "I feel great," into an embedding creation algorithm, I might get back a number that looks like this or an array of numbers that looks like this. Each number inside of this array is kind of like a score that talks about what the text is really discussing. So maybe, this is an example, this is not what the first number actually is, but maybe that first number is kind of a score of how happy the text is. The next number might be talking about how much the text is talking about, I don't know, potatoes. And the next one might be talking about whether the text is discussing hiking a mountain and so on. So again, in these embeddings or these arrays of numbers, we can kind of think of these as being scores that are discussing or kind of rating the raw essence of what the text is talking about. We can create an embedding for any length of text. So we can make a embedding for a very short sentence like this, or for a giant chunk of text or even an entire PDF document. Whenever we put a chunk of text into an embedding creation algorithm, we're always gonna get back probably a slightly different array of numbers. So if I put in, "I feel great," I may get back an array of numbers looks like this. "I'm sad," might be a little bit different. "The sun tastes like jelly beans." It doesn't matter if it doesn't make a lot of sense, we will always get back an array of numbers that look like that. So these are kind of like our text summaries of sorts. Not only do they kind of help us understand what a chunk of text is talking about, but they're also, well, an array of numbers and that means we can do some math on them. And that ends up being really, really handy. Let me show you why in just a moment. So we're gonna repeat that process for every different chunk of text. We're gonna come up with this big list of embeddings. Once we've generated that list of embeddings, we're going to store them inside of a database. We usually refer to these databases that are really specialized in storing in embeddings as vector stores. We can make use of a very traditional database like SQLite or MySQL or whatever else, but again, usually we put them inside of something called a vector store because they're very specialized for handling these embeddings and eventually doing a little bit of math on them as well. Okay, so now, that's kind of the pre-processing step that we've gone over. So now we kind of fast forward to where a user actually submits a question. So the question might be something like, "Where does the word earth come from?" Well, remember, we need to somehow find the most relevant chunk of text that's related to the user's question. So we're going to go through that same, here we go, right here, embedding process. We're gonna take the user's question, we're gonna feed it into that same embedding algorithm and we're gonna generate an embedding corresponding to the user's question. So now we've got kind of a sense in this numerical format of what the user's question was all about. We're then going to take that embedding, here it is right here on the left-hand side, and we're going to do a little bit, like I said, a little bit of special math here that we'll go over in great detail, to find these stored embeddings. Remember, these embeddings over here are the ones for all the chunks of text we had extracted earlier on. And we're gonna find the chunk of text or the embedding that is most relevant to the user's question. So in this case, maybe the most relevant one, we decide is embedding number three right here. So we're then going to take the user's question and the super relevant chunk of text from the PDF. We're gonna take both those and put them into a prompt to send off to ChatGPT. So here's my question. Here's that super relevant chunk of text right here, and we're gonna send them off to ChatGPT inside of a text prompt that might look like this. And I want you to just read this prompt really quickly and just kinda understand the structure of what's going on. So we can kind of think of this as saying, "Hey, ChatGPT. Did you know that," you know, basically the text from the PDF over here on the left-hand side. We're then going to ask our question. And I think anyone given a message like this can probably answer that question. We're basically giving ChatGPT the answer right here, and then we're asking the question. So of course, ChatGPT is almost always gonna give us the exact correct answer every single time and it's gonna be able to use the exact content coming out of the PDF. So we send this all off to ChatGPT, we get back an answer, something like, "Hey, it's coming from this word." And we say, "Hey, this is awesome. ChatGPT somehow read our PDF." Well, not really. ChatGPT is kind of the least interesting part of this entire system. 'Cause all ChatGPT really did was kinda regurgitate this very key critical part of the PDF that we had just sent over to it. Okay, so that's it. That's the entire process. That is what's going on behind the scenes with this app. So now that we've kind of understood this process and we've got an idea of what embeddings are, most critically, and that idea of chunking texts, the idea of looking up embeddings later on, now we're gonna kind of go back and understand why we use LangChain at all and what LangChain is doing for us in this entire process.

Onto the last step here, we're gonna understand why we use LangChain at all. And how it makes building an app like the one we just looked at, way, way easier. So, here we go. Okay, so here's the entire process, we just went through step by step. So user uploads the PDF, we then open the PDF file, get the chunks of text, and so on. We just went over all this. So the reason that we use LangChain, I'm gonna tell you immediately right now, is that it gives us tools to automate every single one of these steps. And I really truly mean every single one of these steps. So let me give you some examples right away. In our application that we're going to eventually build here, we need to eventually open a PDF file and extract the text from it. Now, I don't know about you, but I don't really know how to open a PDF in particular, and get text out of it. Content that is stored inside of a PDF isn't stored in there as plain text. We need to use some kind of parser to get all that text out. So it turns out that LangChain includes a class that we can very easily use, to not only open up a PDF file, but also extract all the content out of it. And this class is called UnstructuredPDFLoader. Super simple to use, I've got an example of it right here. Just a couple of lines of code, to open up PDF and get all the text. LangChain gives us these kind of loader classes that allow us to open up documents and extract text outta them, not only for PDFs, but for many other file types as well. So we get classes that help us load up JSON from a file, load up HTML from a file. We also get classes that help us load up files that are stored on remote servers, like maybe Amazon S3. Or load up files from a Discord server, or from an Excel file, or from a GitHub issue or from Google Drive, and many, many other places. So the first thing that we're starting to realize here, is that LangChain gives us the ability to load up data from just about any source imaginable. Let's move on to the next step. So we just took a look at opening a PDF file and parsing text. And I think you can agree with me, that yeah, if we use LangChain, seems like this is kind of easy, right? So, let's now move on to, we're gonna skip a couple steps here, and go to a more interesting one, where we store results inside of a database, or a vector store. Remember, this is where we take those embeddings, and we put them into a very specialized database. There are a ton of very popular vector databases out there right now, an incredible number, because there are a lot of companies who are trying to cash in, to this focus on embeddings, which is super key right now, inside the AI space. So I've got just a couple examples of databases, that are specialized for handling vectors. There's PGVector, which is an extension that sits on top of Postgres. There's a startup called Pinecone. There's another startup called Chroma. There's Deep Lake, there's Weaviate, there's Redis, and there's a whole ton of other databases that are specialized in handling these embeddings. And if we wanted to use these on a project, well, we could spend a lot of time to figure out how each one works, and access it from our code. Or, you guessed it, we could just make use of some classes that are included inside of LangChain, that completely wrap up the usage of these vector databases and makes using them incredibly simple. So here's an example of using PGVector, Redis, Pinecone, Weaviate. And even though a little bit of the code sometimes looks a little bit different, some of these options here are a little bit different from example to example, you'll notice that the general structure of the code is just about identical. We create some kind of object right here. We then have our question. And to find relevant embeddings, we call a method called similarity search. So it's same thing for PGVector, as Redis, as Pinecone, and Weaviate. So we can repeat this process. I could walk you through all these other features, or all these other steps we had to go through, but it's all basically the same as the two we just looked at. The reason we use Chat GPT, is that it gives us this set of interchangeable tools, really these interchangeable classes, that help us automate every single step of a text generation pipeline, like the one that's being used, inside of that PDF.ai app. So LangChain has tools for loading data, parsing it, creating embeddings, storing those embeddings, querying those embeddings, and then taking fetch embeddings, or generated embeddings, and eventually sending them off to Chat GPT. We get sets of tools for integrating with a ton of different databases, a ton of different data storage platforms, just about everything you can imagine. And most importantly, it's generally pretty easy to swap out these different providers. So for example, if we don't wanna use say, Chat GPT anymore, we can very easily swap in a completely different model, in a handful of minutes. Maybe we don't like the vector database we're using, we wanna use a different one. Again, we can swap it out, in a handful of minutes. And this is what LangChain is all about. It's about giving us these interchangeable tools that make it really easy for us to first generate a pipeline or create this pipeline, and then change these parts out over time, as the goals of our project or product change. Okay, so that's it. Now you got a reasonable idea of what LangChain is all about, or at least what its goals are. But we've still not really looked at a lot of code, so quick pause right here, and we'll get started on our first project in just a moment.